# AI Governance Policy - TechCorp Brasil
## PolÃ­tica de GovernanÃ§a de InteligÃªncia Artificial (Exemplo Baseado em Melhores PrÃ¡ticas)

> **Nota**: Este documento Ã© um exemplo educacional baseado em frameworks pÃºblicos de IA responsÃ¡vel (Microsoft, Google, NIST) e requisitos regulatÃ³rios brasileiros. Foi elaborado para fins de aprendizado no contexto do MBA em CiberseguranÃ§a & IA.

---

## InformaÃ§Ãµes do Documento

| Campo | Valor |
|-------|-------|
| **OrganizaÃ§Ã£o** | TechCorp Brasil S.A. (Exemplo FictÃ­cio) |
| **VersÃ£o** | 1.0 |
| **Data de AprovaÃ§Ã£o** | Janeiro 2025 |
| **PrÃ³xima RevisÃ£o** | Janeiro 2026 |
| **ProprietÃ¡rio** | Chief AI Officer (CAIO) |
| **ClassificaÃ§Ã£o** | Interno |

---

## 1. IntroduÃ§Ã£o

### 1.1 PropÃ³sito

Esta polÃ­tica estabelece os princÃ­pios, diretrizes e controles para o desenvolvimento, implantaÃ§Ã£o e uso responsÃ¡vel de sistemas de InteligÃªncia Artificial (IA) na TechCorp Brasil, garantindo que tais sistemas sejam seguros, Ã©ticos, transparentes e alinhados com:

- Valores organizacionais
- LegislaÃ§Ã£o brasileira (LGPD, Marco Civil, futuro Marco Legal de IA)
- RegulamentaÃ§Ãµes setoriais aplicÃ¡veis
- Melhores prÃ¡ticas internacionais (NIST AI RMF, ISO 42001)

### 1.2 Escopo

Esta polÃ­tica se aplica a:

| Categoria | IncluÃ­do |
|-----------|----------|
| Sistemas de IA desenvolvidos internamente | âœ… |
| Sistemas de IA adquiridos de terceiros | âœ… |
| APIs e serviÃ§os de IA externos (OpenAI, Azure, Google) | âœ… |
| Large Language Models (LLMs) | âœ… |
| Modelos de Machine Learning (ML) | âœ… |
| AutomaÃ§Ãµes baseadas em regras (nÃ£o-IA) | âŒ |
| Analytics tradicional | âŒ |

**AudiÃªncia**: Todos os colaboradores, contratados e terceiros que desenvolvem, implementam ou utilizam sistemas de IA.

### 1.3 DefiniÃ§Ãµes

| Termo | DefiniÃ§Ã£o |
|-------|-----------|
| **InteligÃªncia Artificial (IA)** | Sistemas computacionais capazes de realizar tarefas que tipicamente requerem inteligÃªncia humana, incluindo aprendizado, raciocÃ­nio e tomada de decisÃ£o |
| **Machine Learning (ML)** | Subconjunto de IA onde sistemas aprendem padrÃµes a partir de dados |
| **Large Language Model (LLM)** | Modelos de IA treinados em grandes volumes de texto para gerar linguagem natural |
| **Sistema de IA de Alto Risco** | Sistema cujo uso pode impactar significativamente direitos fundamentais, saÃºde, seguranÃ§a ou bem-estar de indivÃ­duos |
| **Explicabilidade (XAI)** | Capacidade de explicar como um sistema de IA chegou a uma decisÃ£o ou output |
| **ViÃ©s (Bias)** | PadrÃµes sistemÃ¡ticos nos dados ou algoritmos que geram resultados injustos ou discriminatÃ³rios |
| **Data Poisoning** | Ataque onde dados maliciosos sÃ£o inseridos no treinamento para comprometer o modelo |
| **Prompt Injection** | Ataque onde inputs maliciosos manipulam o comportamento de um LLM |

---

## 2. PrincÃ­pios Fundamentais

### 2.1 Os Seis PrincÃ­pios de IA ResponsÃ¡vel da TechCorp

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRINCÃPIOS DE IA RESPONSÃVEL - TECHCORP                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚         â”‚  SEGURANÃ‡A  â”‚         â”‚TRANSPARÃŠNCIAâ”‚         â”‚   JUSTIÃ‡A   â”‚         â”‚
â”‚         â”‚  & PROTEÃ‡ÃƒO â”‚         â”‚& EXPLICABIL.â”‚         â”‚ & EQUIDADE  â”‚         â”‚
â”‚         â”‚             â”‚         â”‚             â”‚         â”‚             â”‚         â”‚
â”‚         â”‚ Sistemas    â”‚         â”‚ DecisÃµes    â”‚         â”‚ IA nÃ£o deve â”‚         â”‚
â”‚         â”‚ seguros,    â”‚         â”‚ compreensÃ­- â”‚         â”‚ discriminar â”‚         â”‚
â”‚         â”‚ resilientes â”‚         â”‚ veis        â”‚         â”‚ ou perpetuarâ”‚         â”‚
â”‚         â”‚ e protegidosâ”‚         â”‚ e auditÃ¡veisâ”‚         â”‚ vieses      â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚         â”‚ PRIVACIDADE â”‚         â”‚ACCOUNTABILITYâ”‚        â”‚ BENEFICÃŠNCIAâ”‚         â”‚
â”‚         â”‚  & DADOS    â”‚         â”‚& GOVERNANÃ‡A â”‚         â”‚  & IMPACTO  â”‚         â”‚
â”‚         â”‚             â”‚         â”‚             â”‚         â”‚             â”‚         â”‚
â”‚         â”‚ ProteÃ§Ã£o de â”‚         â”‚ Responsabi- â”‚         â”‚ IA deve     â”‚         â”‚
â”‚         â”‚ dados       â”‚         â”‚ lidades     â”‚         â”‚ gerar valor â”‚         â”‚
â”‚         â”‚ pessoais e  â”‚         â”‚ claramente  â”‚         â”‚ positivo    â”‚         â”‚
â”‚         â”‚ conformidadeâ”‚         â”‚ definidas   â”‚         â”‚ para todos  â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              SUPERVISÃƒO HUMANA (Human-in-the-Loop)                         â”‚  â”‚
â”‚  â”‚                                                                            â”‚  â”‚
â”‚  â”‚   Humanos mantÃªm controle e capacidade de override sobre decisÃµes         â”‚  â”‚
â”‚  â”‚   crÃ­ticas de IA. Nenhuma decisÃ£o que afete significativamente            â”‚  â”‚
â”‚  â”‚   indivÃ­duos Ã© totalmente automatizada sem revisÃ£o humana.                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Detalhamento dos PrincÃ­pios

| PrincÃ­pio | Compromissos | MÃ©tricas |
|-----------|--------------|----------|
| **SeguranÃ§a** | Testes rigorosos, monitoramento contÃ­nuo, resposta a incidentes, proteÃ§Ã£o contra ataques adversariais | Zero incidentes crÃ­ticos de seguranÃ§a de IA |
| **TransparÃªncia** | DocumentaÃ§Ã£o completa (Model Cards), explicabilidade, comunicaÃ§Ã£o clara aos usuÃ¡rios | 100% dos modelos com Model Card |
| **JustiÃ§a** | Testes de fairness, auditorias de viÃ©s, correÃ§Ã£o proativa | Disparidade < 5% entre grupos demogrÃ¡ficos |
| **Privacidade** | LGPD compliance, minimizaÃ§Ã£o de dados, privacy by design | 100% conformidade LGPD |
| **Accountability** | PapÃ©is claros, trilhas de auditoria, governanÃ§a robusta | Rastreabilidade completa de decisÃµes |
| **BeneficÃªncia** | AvaliaÃ§Ã£o de impacto, alinhamento com valores, benefÃ­cio social | Net positive impact assessment |

---

## 3. Estrutura de GovernanÃ§a

### 3.1 Organograma de GovernanÃ§a de IA

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    Conselho de Admin.   â”‚
                        â”‚  (SupervisÃ£o Executiva) â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    ComitÃª de Ã‰tica      â”‚
                        â”‚    e IA ResponsÃ¡vel     â”‚
                        â”‚    (AI Ethics Board)    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                          â”‚                          â”‚
         â–¼                          â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      CAIO       â”‚      â”‚      CISO       â”‚      â”‚       DPO       â”‚
â”‚  (AI Officer)   â”‚      â”‚   (SeguranÃ§a)   â”‚      â”‚  (Privacidade)  â”‚
â”‚                 â”‚      â”‚                 â”‚      â”‚                 â”‚
â”‚ â€¢ EstratÃ©gia IA â”‚      â”‚ â€¢ SeguranÃ§a IA  â”‚      â”‚ â€¢ LGPD/DPIA     â”‚
â”‚ â€¢ GovernanÃ§a    â”‚      â”‚ â€¢ Red Team IA   â”‚      â”‚ â€¢ Direitos      â”‚
â”‚ â€¢ Ã‰tica         â”‚      â”‚ â€¢ Incidentes    â”‚      â”‚ â€¢ Consentimento â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI/ML Team    â”‚      â”‚  Security Team  â”‚      â”‚   Legal Team    â”‚
â”‚                 â”‚      â”‚                 â”‚      â”‚                 â”‚
â”‚ â€¢ Data Science  â”‚      â”‚ â€¢ AppSec        â”‚      â”‚ â€¢ Contratos     â”‚
â”‚ â€¢ MLOps         â”‚      â”‚ â€¢ MLSecOps      â”‚      â”‚ â€¢ RegulatÃ³rio   â”‚
â”‚ â€¢ AI Engineers  â”‚      â”‚ â€¢ SOC           â”‚      â”‚ â€¢ Compliance    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 ComitÃª de Ã‰tica e IA ResponsÃ¡vel

| Responsabilidade | FrequÃªncia |
|-----------------|------------|
| Revisar e aprovar projetos de IA de alto risco | Por projeto |
| Avaliar conformidade com princÃ­pios Ã©ticos | Trimestral |
| Revisar incidentes relacionados a IA | Conforme necessÃ¡rio |
| Atualizar polÃ­ticas e diretrizes | Anual |
| Acompanhar evoluÃ§Ã£o regulatÃ³ria | ContÃ­nuo |
| Aprovar uso de LLMs externos | Por solicitaÃ§Ã£o |

**ComposiÃ§Ã£o**:
- CAIO (Presidente)
- CISO
- DPO
- Head of Engineering
- Head of Legal
- Representante de RH
- Representante de Compliance
- Especialista externo em Ã©tica (consultivo)

### 3.3 Matriz RACI para GovernanÃ§a de IA

| Atividade | CAIO | CISO | DPO | AI Team | Business |
|-----------|------|------|-----|---------|----------|
| Definir estratÃ©gia de IA | **A** | C | C | R | C |
| Aprovar projetos alto risco | **A** | R | R | I | C |
| Avaliar seguranÃ§a de IA | C | **A** | I | R | I |
| Conduzir DPIA | C | C | **A** | R | C |
| Desenvolver modelos | C | C | I | **A/R** | C |
| Monitorar modelos em produÃ§Ã£o | C | R | I | **A** | I |
| Responder a incidentes de IA | R | **A** | C | R | I |
| Treinar funcionÃ¡rios | R | R | R | C | **A** |

*R=Responsible, A=Accountable, C=Consulted, I=Informed*

---

## 4. ClassificaÃ§Ã£o de Risco de Sistemas de IA

### 4.1 Matriz de ClassificaÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLASSIFICAÃ‡ÃƒO DE RISCO DE SISTEMAS DE IA                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  Impacto em IndivÃ­duos                                                           â”‚
â”‚        â”‚                                                                         â”‚
â”‚  Alto  â”‚   MÃ‰DIO    â”‚    ALTO     â”‚   CRÃTICO                                   â”‚
â”‚        â”‚            â”‚             â”‚                                              â”‚
â”‚  MÃ©dio â”‚   BAIXO    â”‚    MÃ‰DIO    â”‚    ALTO                                     â”‚
â”‚        â”‚            â”‚             â”‚                                              â”‚
â”‚  Baixo â”‚   BAIXO    â”‚    BAIXO    â”‚    MÃ‰DIO                                    â”‚
â”‚        â”‚            â”‚             â”‚                                              â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶                                â”‚
â”‚              Baixa       MÃ©dia        Alta                                       â”‚
â”‚                    Escala de Uso/AutomaÃ§Ã£o                                       â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 NÃ­veis de Risco e Exemplos

| NÃ­vel | DescriÃ§Ã£o | Exemplos na TechCorp | Controles ObrigatÃ³rios |
|-------|-----------|---------------------|----------------------|
| **CrÃ­tico** | DecisÃµes automatizadas que afetam significativamente direitos ou bem-estar | Scoring de crÃ©dito, triagem de RH, detecÃ§Ã£o de fraude com bloqueio automÃ¡tico | DPIA, ComitÃª, Explicabilidade, Human Override, Auditoria Externa |
| **Alto** | Impacto significativo em operaÃ§Ãµes ou clientes | RecomendaÃ§Ãµes de produtos, chatbots de atendimento, precificaÃ§Ã£o dinÃ¢mica | DPIA, Model Card, Fairness Testing, Monitoramento |
| **MÃ©dio** | Impacto moderado, decisÃµes assistivas | ClassificaÃ§Ã£o de tickets, summarizaÃ§Ã£o, detecÃ§Ã£o de anomalias | Model Card, Testes, Monitoramento |
| **Baixo** | Impacto mÃ­nimo, uso interno | AutomaÃ§Ã£o de tarefas internas, PoCs, experimentos | DocumentaÃ§Ã£o bÃ¡sica |

### 4.3 Uso Proibido de IA

Ã‰ **expressamente proibido** usar IA para:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                           USO PROIBIDO DE IA                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                   â•‘
â•‘  âŒ DecisÃµes automatizadas sobre indivÃ­duos sem possibilidade de revisÃ£o humana  â•‘
â•‘                                                                                   â•‘
â•‘  âŒ VigilÃ¢ncia ou monitoramento invasivo de funcionÃ¡rios                         â•‘
â•‘                                                                                   â•‘
â•‘  âŒ GeraÃ§Ã£o de deepfakes, desinformaÃ§Ã£o ou conteÃºdo enganoso                     â•‘
â•‘                                                                                   â•‘
â•‘  âŒ DiscriminaÃ§Ã£o baseada em atributos protegidos (raÃ§a, gÃªnero, religiÃ£o, etc.) â•‘
â•‘                                                                                   â•‘
â•‘  âŒ ManipulaÃ§Ã£o psicolÃ³gica ou exploraÃ§Ã£o de vulnerabilidades                    â•‘
â•‘                                                                                   â•‘
â•‘  âŒ Sistemas de pontuaÃ§Ã£o social ou citizen scoring                              â•‘
â•‘                                                                                   â•‘
â•‘  âŒ Reconhecimento facial para vigilÃ¢ncia em massa                               â•‘
â•‘                                                                                   â•‘
â•‘  âŒ Armas autÃ´nomas ou sistemas letais                                           â•‘
â•‘                                                                                   â•‘
â•‘  âŒ Qualquer atividade ilegal ou antiÃ©tica                                       â•‘
â•‘                                                                                   â•‘
â•‘  âŒ Contornar controles de seguranÃ§a                                             â•‘
â•‘                                                                                   â•‘
â•‘  ViolaÃ§Ãµes resultarÃ£o em medidas disciplinares, incluindo demissÃ£o.              â•‘
â•‘                                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 5. Ciclo de Vida de Sistemas de IA

### 5.1 Framework de Desenvolvimento Seguro (AI-DevSecOps)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CICLO DE VIDA AI-DEVSECOPS                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚   IDEAÃ‡ÃƒO         DESIGN          BUILD           DEPLOY         OPERATE        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€        â”‚
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚Business â”‚    â”‚Risk     â”‚    â”‚Secure   â”‚    â”‚Approval â”‚    â”‚Monitor  â”‚       â”‚
â”‚  â”‚Case     â”‚â”€â”€â”€â–¶â”‚Assess   â”‚â”€â”€â”€â–¶â”‚Develop  â”‚â”€â”€â”€â–¶â”‚Gate     â”‚â”€â”€â”€â–¶â”‚& Improveâ”‚       â”‚
â”‚  â”‚         â”‚    â”‚         â”‚    â”‚         â”‚    â”‚         â”‚    â”‚         â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚              â”‚              â”‚              â”‚              â”‚             â”‚
â”‚       â–¼              â–¼              â–¼              â–¼              â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚â€¢ Use    â”‚    â”‚â€¢ DPIA   â”‚    â”‚â€¢ Data   â”‚    â”‚â€¢ Model  â”‚    â”‚â€¢ Drift  â”‚       â”‚
â”‚  â”‚  Case   â”‚    â”‚â€¢ Ethics â”‚    â”‚  Valid. â”‚    â”‚  Card   â”‚    â”‚  Detect â”‚       â”‚
â”‚  â”‚â€¢ Risk   â”‚    â”‚  Review â”‚    â”‚â€¢ Fair-  â”‚    â”‚â€¢ ComitÃª â”‚    â”‚â€¢ Fairnessâ”‚      â”‚
â”‚  â”‚  Class  â”‚    â”‚â€¢ Archi- â”‚    â”‚  ness   â”‚    â”‚  (se    â”‚    â”‚â€¢ Retrainâ”‚       â”‚
â”‚  â”‚â€¢ Sponsorâ”‚    â”‚  tectureâ”‚    â”‚â€¢ Securityâ”‚   â”‚  crÃ­ticoâ”‚    â”‚â€¢ Audit  â”‚       â”‚
â”‚  â”‚â€¢ Approveâ”‚    â”‚â€¢ Data   â”‚    â”‚  Tests  â”‚    â”‚â€¢ Deploy â”‚    â”‚â€¢ Incidentâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  Requireâ”‚    â”‚â€¢ Explainâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                                  â”‚
â”‚  GATE 1         GATE 2         GATE 3          GATE 4         CONTÃNUO          â”‚
â”‚  AprovaÃ§Ã£o      DPIA +         Security +      ProduÃ§Ã£o       Monitoramento     â”‚
â”‚  Inicial        Ethics         Fairness        Release        & Melhoria        â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Requisitos por Gate

#### Gate 1: IdeaÃ§Ã£o â†’ Design
| Requisito | Baixo | MÃ©dio | Alto | CrÃ­tico |
|-----------|-------|-------|------|---------|
| Business case documentado | âœ… | âœ… | âœ… | âœ… |
| ClassificaÃ§Ã£o de risco | âœ… | âœ… | âœ… | âœ… |
| Sponsor definido | âœ… | âœ… | âœ… | âœ… |
| AprovaÃ§Ã£o CAIO | âŒ | âŒ | âœ… | âœ… |
| AprovaÃ§Ã£o ComitÃª | âŒ | âŒ | âŒ | âœ… |

#### Gate 2: Design â†’ Build
| Requisito | Baixo | MÃ©dio | Alto | CrÃ­tico |
|-----------|-------|-------|------|---------|
| Arquitetura documentada | âœ… | âœ… | âœ… | âœ… |
| Requisitos de dados | âœ… | âœ… | âœ… | âœ… |
| DPIA | âŒ | âŒ | âœ… | âœ… |
| RevisÃ£o Ã©tica | âŒ | âŒ | âœ… | âœ… |
| Security architecture | âŒ | âœ… | âœ… | âœ… |

#### Gate 3: Build â†’ Deploy
| Requisito | Baixo | MÃ©dio | Alto | CrÃ­tico |
|-----------|-------|-------|------|---------|
| Testes funcionais | âœ… | âœ… | âœ… | âœ… |
| Testes de seguranÃ§a | âŒ | âœ… | âœ… | âœ… |
| Testes de fairness | âŒ | âŒ | âœ… | âœ… |
| Adversarial testing | âŒ | âŒ | âœ… | âœ… |
| Model Card | âŒ | âœ… | âœ… | âœ… |
| Explicabilidade validada | âŒ | âŒ | âœ… | âœ… |

#### Gate 4: Deploy â†’ Operate
| Requisito | Baixo | MÃ©dio | Alto | CrÃ­tico |
|-----------|-------|-------|------|---------|
| Monitoramento configurado | âœ… | âœ… | âœ… | âœ… |
| Plano de rollback | âŒ | âœ… | âœ… | âœ… |
| Treinamento de usuÃ¡rios | âŒ | âŒ | âœ… | âœ… |
| AprovaÃ§Ã£o final ComitÃª | âŒ | âŒ | âŒ | âœ… |
| Human override configurado | âŒ | âŒ | âœ… | âœ… |

---

## 6. Uso de LLMs e IA Generativa

### 6.1 Ferramentas Aprovadas

| Ferramenta | Status | Uso Permitido | RestriÃ§Ãµes |
|------------|--------|---------------|------------|
| **Azure OpenAI Service** | âœ… Aprovado | Desenvolvimento, produÃ§Ã£o | Dados confidenciais permitidos com controles |
| **GitHub Copilot Enterprise** | âœ… Aprovado | Desenvolvimento de cÃ³digo | NÃ£o usar para cÃ³digo de seguranÃ§a crÃ­tica |
| **ChatGPT Enterprise** | âœ… Aprovado | Produtividade geral | Sem dados de clientes ou PII |
| **ChatGPT (consumer)** | âš ï¸ Restrito | Pesquisa pessoal apenas | **PROIBIDO dados corporativos** |
| **Claude (API)** | âœ… Aprovado | Desenvolvimento | Via API com controles |
| **Midjourney/DALL-E** | âš ï¸ Restrito | Marketing apenas | AprovaÃ§Ã£o prÃ©via necessÃ¡ria |
| **Modelos open source** | ğŸ“‹ Caso a caso | Desenvolvimento | AvaliaÃ§Ã£o de seguranÃ§a obrigatÃ³ria |

### 6.2 PolÃ­tica de Dados para LLMs

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    CLASSIFICAÃ‡ÃƒO DE DADOS PARA USO EM LLMs                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                   â•‘
â•‘  âœ… PERMITIDO (com ferramentas aprovadas):                                        â•‘
â•‘     â€¢ InformaÃ§Ãµes pÃºblicas                                                        â•‘
â•‘     â€¢ DocumentaÃ§Ã£o tÃ©cnica genÃ©rica                                               â•‘
â•‘     â€¢ CÃ³digo nÃ£o-proprietÃ¡rio                                                     â•‘
â•‘     â€¢ Dados de teste sintÃ©ticos                                                   â•‘
â•‘                                                                                   â•‘
â•‘  âš ï¸  REQUER APROVAÃ‡ÃƒO:                                                            â•‘
â•‘     â€¢ CÃ³digo proprietÃ¡rio                                                         â•‘
â•‘     â€¢ Documentos internos                                                         â•‘
â•‘     â€¢ InformaÃ§Ãµes de projetos                                                     â•‘
â•‘                                                                                   â•‘
â•‘  âŒ PROIBIDO (mesmo em ferramentas aprovadas):                                    â•‘
â•‘     â€¢ PII de clientes (CPF, cartÃ£o, biometria)                                   â•‘
â•‘     â€¢ Dados financeiros de clientes                                               â•‘
â•‘     â€¢ Credenciais, senhas, API keys                                              â•‘
â•‘     â€¢ Segredos comerciais                                                         â•‘
â•‘     â€¢ InformaÃ§Ãµes de M&A nÃ£o pÃºblicas                                            â•‘
â•‘     â€¢ Dados de saÃºde                                                              â•‘
â•‘     â€¢ ComunicaÃ§Ãµes privilegiadas (legal)                                          â•‘
â•‘                                                                                   â•‘
â•‘  LEMBRE-SE: Quando em dÃºvida, NÃƒO envie. Consulte o time de seguranÃ§a.           â•‘
â•‘                                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 6.3 Controles TÃ©cnicos para LLMs

| Controle | ImplementaÃ§Ã£o | Status |
|----------|---------------|--------|
| **DLP Gateway** | Proxy que analisa todos os prompts antes de enviar | âœ… ProduÃ§Ã£o |
| **ClassificaÃ§Ã£o automÃ¡tica** | ML que detecta dados sensÃ­veis em prompts | âœ… ProduÃ§Ã£o |
| **Logging centralizado** | Todas as interaÃ§Ãµes logadas (sem PII) | âœ… ProduÃ§Ã£o |
| **Limite de tokens** | MÃ¡ximo 8K tokens por request | âœ… Configurado |
| **Guardrails** | Filtros de input/output | âœ… Azure, em progresso para outros |
| **Monitoramento de uso** | Dashboard de uso por usuÃ¡rio/departamento | âœ… ProduÃ§Ã£o |

---

## 7. Fairness e NÃ£o-DiscriminaÃ§Ã£o

### 7.1 Atributos Protegidos (Brasil)

De acordo com a legislaÃ§Ã£o brasileira (ConstituiÃ§Ã£o, CLT, LGPD), os seguintes atributos requerem atenÃ§Ã£o especial:

| Atributo | Base Legal | Monitoramento |
|----------|------------|---------------|
| RaÃ§a e cor | CF Art. 5Âº, Lei 7.716/89 | ObrigatÃ³rio |
| GÃªnero | CF Art. 5Âº, CLT | ObrigatÃ³rio |
| Idade | CF Art. 7Âº, Estatuto do Idoso | ObrigatÃ³rio |
| DeficiÃªncia | Lei 13.146/2015 | ObrigatÃ³rio |
| ReligiÃ£o | CF Art. 5Âº | Recomendado |
| OrientaÃ§Ã£o sexual | STF ADO 26 | Recomendado |
| Origem geogrÃ¡fica | CF Art. 5Âº | Recomendado |
| SituaÃ§Ã£o familiar | CLT Art. 391 | Recomendado |

### 7.2 MÃ©tricas de Fairness ObrigatÃ³rias

Para sistemas de Alto Risco e CrÃ­ticos:

| MÃ©trica | DefiniÃ§Ã£o | Threshold |
|---------|-----------|-----------|
| **Demographic Parity** | Taxa de resultado positivo igual entre grupos | DiferenÃ§a < 5% |
| **Equalized Odds** | TPR e FPR similares entre grupos | DiferenÃ§a < 5% |
| **Disparate Impact Ratio** | Ratio de taxas de seleÃ§Ã£o | Entre 0.8 e 1.25 |

### 7.3 Processo de Auditoria de Fairness

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESSO DE AUDITORIA DE FAIRNESS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  1. PRÃ‰-DEPLOY                                                                   â”‚
â”‚     â”œâ”€â”€ Definir grupos demogrÃ¡ficos relevantes                                  â”‚
â”‚     â”œâ”€â”€ Escolher mÃ©tricas de fairness apropriadas                               â”‚
â”‚     â”œâ”€â”€ Estabelecer thresholds aceitÃ¡veis                                       â”‚
â”‚     â””â”€â”€ Executar testes em dataset de validaÃ§Ã£o                                 â”‚
â”‚                                                                                  â”‚
â”‚  2. DEPLOY                                                                       â”‚
â”‚     â”œâ”€â”€ Verificar fairness metrics nos primeiros 30 dias                        â”‚
â”‚     â”œâ”€â”€ Comparar com baseline prÃ©-deploy                                        â”‚
â”‚     â””â”€â”€ Documentar resultados                                                   â”‚
â”‚                                                                                  â”‚
â”‚  3. MONITORAMENTO CONTÃNUO                                                       â”‚
â”‚     â”œâ”€â”€ Dashboard de fairness atualizado diariamente                            â”‚
â”‚     â”œâ”€â”€ Alertas automÃ¡ticos se threshold violado                                â”‚
â”‚     â””â”€â”€ RevisÃ£o mensal de mÃ©tricas                                              â”‚
â”‚                                                                                  â”‚
â”‚  4. AUDITORIA PERIÃ“DICA                                                          â”‚
â”‚     â”œâ”€â”€ Trimestral: RevisÃ£o interna                                             â”‚
â”‚     â”œâ”€â”€ Anual: Auditoria externa (para crÃ­ticos)                                â”‚
â”‚     â””â”€â”€ DocumentaÃ§Ã£o para compliance                                            â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. SeguranÃ§a de IA

### 8.1 AmeaÃ§as EspecÃ­ficas de IA

| AmeaÃ§a | DescriÃ§Ã£o | Controle |
|--------|-----------|----------|
| **Data Poisoning** | Corromper dados de treinamento | ValidaÃ§Ã£o de dados, proveniÃªncia |
| **Model Extraction** | Roubar modelo via API | Rate limiting, watermarking |
| **Adversarial Attacks** | Inputs crafted para enganar modelo | Adversarial training, input validation |
| **Prompt Injection** | Manipular LLMs via prompts maliciosos | Guardrails, input sanitization |
| **Model Inversion** | Extrair dados de treino do modelo | Differential privacy, output limiting |
| **Membership Inference** | Descobrir se dados especÃ­ficos foram usados | DP-SGD, federated learning |

### 8.2 Requisitos de SeguranÃ§a por ClassificaÃ§Ã£o

| Controle | Baixo | MÃ©dio | Alto | CrÃ­tico |
|----------|-------|-------|------|---------|
| Criptografia em repouso | âœ… | âœ… | âœ… | âœ… |
| Criptografia em trÃ¢nsito | âœ… | âœ… | âœ… | âœ… |
| Rate Limiting | âŒ | âœ… | âœ… | âœ… |
| Input Validation | âŒ | âœ… | âœ… | âœ… |
| Output Filtering | âŒ | âŒ | âœ… | âœ… |
| Adversarial Testing | âŒ | âŒ | âœ… | âœ… |
| Red Team | âŒ | âŒ | âŒ | âœ… |
| Model Signing | âŒ | âœ… | âœ… | âœ… |
| Monitoramento de Drift | âŒ | âœ… | âœ… | âœ… |
| Audit Logging | BÃ¡sico | Detalhado | Completo | Completo + ImutÃ¡vel |

---

## 9. TransparÃªncia e Explicabilidade

### 9.1 Requisitos de TransparÃªncia

| Requisito | DescriÃ§Ã£o | ObrigatÃ³rio para |
|-----------|-----------|------------------|
| **Model Card** | DocumentaÃ§Ã£o padronizada do modelo | MÃ©dio+ |
| **Aviso de uso de IA** | Informar usuÃ¡rios quando interagem com IA | Alto/CrÃ­tico |
| **ExplicaÃ§Ã£o de decisÃµes** | Capacidade de explicar outputs | CrÃ­tico |
| **Direito de contestaÃ§Ã£o** | Processo para questionar decisÃµes | CrÃ­tico |
| **Recurso humano** | OpÃ§Ã£o de revisÃ£o por humano | Alto/CrÃ­tico |

### 9.2 Template de Model Card (Resumido)

Todo modelo de classificaÃ§Ã£o MÃ©dia ou superior deve ter um Model Card contendo:

1. **InformaÃ§Ãµes bÃ¡sicas**: Nome, versÃ£o, data, proprietÃ¡rio
2. **Uso pretendido**: Casos de uso aprovados e nÃ£o aprovados
3. **Dados de treinamento**: DescriÃ§Ã£o (sem expor dados sensÃ­veis)
4. **MÃ©tricas de performance**: Accuracy, precision, recall, etc.
5. **MÃ©tricas de fairness**: Demographic parity, equalized odds
6. **LimitaÃ§Ãµes conhecidas**: Quando o modelo pode falhar
7. **ConsideraÃ§Ãµes Ã©ticas**: Riscos identificados e mitigaÃ§Ãµes

---

## 10. Conformidade RegulatÃ³ria

### 10.1 Mapeamento RegulatÃ³rio

| RegulamentaÃ§Ã£o | JurisdiÃ§Ã£o | Status | Requisitos Chave |
|----------------|------------|--------|------------------|
| **LGPD** | Brasil | Em vigor | Consentimento, DPIA, direitos do titular, Art. 20 (decisÃµes automatizadas) |
| **PL 2338/2023 (Marco IA)** | Brasil | Em tramitaÃ§Ã£o | ClassificaÃ§Ã£o de risco, transparÃªncia, direitos |
| **ResoluÃ§Ã£o 4.893 BACEN** | Brasil (Financeiro) | Em vigor | SeguranÃ§a cibernÃ©tica em sistemas crÃ­ticos |
| **GDPR Art. 22** | UE | Em vigor | Direito de nÃ£o estar sujeito a decisÃ£o automatizada |
| **AI Act** | UE | Em vigor | ClassificaÃ§Ã£o de risco, proibiÃ§Ãµes, requisitos |

### 10.2 LGPD Art. 20 - DecisÃµes Automatizadas

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              LGPD ART. 20 - DIREITO DE REVISÃƒO DE DECISÃ•ES AUTOMATIZADAS         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                   â•‘
â•‘  "O titular dos dados tem direito a solicitar a revisÃ£o de decisÃµes tomadas      â•‘
â•‘   unicamente com base em tratamento automatizado de dados pessoais que           â•‘
â•‘   afetem seus interesses, incluÃ­das as decisÃµes destinadas a definir o seu       â•‘
â•‘   perfil pessoal, profissional, de consumo e de crÃ©dito ou os aspectos           â•‘
â•‘   de sua personalidade."                                                         â•‘
â•‘                                                                                   â•‘
â•‘  OBRIGAÃ‡Ã•ES DA TECHCORP:                                                          â•‘
â•‘                                                                                   â•‘
â•‘  1. Informar quando decisÃµes sÃ£o automatizadas                                   â•‘
â•‘  2. Fornecer informaÃ§Ãµes claras sobre lÃ³gica utilizada                          â•‘
â•‘  3. Permitir revisÃ£o humana quando solicitado                                    â•‘
â•‘  4. Responder em 15 dias                                                         â•‘
â•‘  5. Documentar todas as solicitaÃ§Ãµes e respostas                                â•‘
â•‘                                                                                   â•‘
â•‘  PROCESSO DE REVISÃƒO:                                                             â•‘
â•‘  â€¢ Canal: privacidade@techcorp.com.br                                            â•‘
â•‘  â€¢ SLA: 15 dias corridos                                                         â•‘
â•‘  â€¢ ResponsÃ¡vel: DPO                                                              â•‘
â•‘                                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 11. Treinamento e ConscientizaÃ§Ã£o

### 11.1 Programa de Treinamento

| PÃºblico | Treinamento | FrequÃªncia | DuraÃ§Ã£o |
|---------|-------------|------------|---------|
| Todos os funcionÃ¡rios | Fundamentos de IA ResponsÃ¡vel | Onboarding + Anual | 2h |
| Desenvolvedores | AI-DevSecOps, SeguranÃ§a de ML | Onboarding + Anual | 8h |
| Data Scientists | MLSecOps, Fairness, Privacy | Onboarding + Anual | 16h |
| Gestores | GovernanÃ§a de IA, Riscos | Onboarding + Anual | 4h |
| LideranÃ§a | EstratÃ©gia e Ã‰tica de IA | Anual | 2h |

### 11.2 ConteÃºdo ObrigatÃ³rio

- [ ] PrincÃ­pios de IA responsÃ¡vel da TechCorp
- [ ] Esta polÃ­tica de governanÃ§a de IA
- [ ] Uso permitido e proibido de ferramentas de IA
- [ ] Caso Samsung: o que NÃƒO fazer com LLMs
- [ ] Como reportar preocupaÃ§Ãµes Ã©ticas
- [ ] Processo de aprovaÃ§Ã£o de projetos de IA

---

## 12. Monitoramento e MÃ©tricas

### 12.1 KPIs de GovernanÃ§a de IA

| MÃ©trica | Meta | FrequÃªncia |
|---------|------|------------|
| % de sistemas de IA inventariados | 100% | Mensal |
| % de sistemas com Model Card | 100% (MÃ©dio+) | Mensal |
| Incidentes de IA | 0 crÃ­ticos | Mensal |
| Tempo mÃ©dio de aprovaÃ§Ã£o de projetos | < 10 dias | Mensal |
| Treinamento completado | > 95% | Trimestral |
| Auditorias de fairness realizadas | 100% (Alto/CrÃ­tico) | Trimestral |
| ReclamaÃ§Ãµes LGPD Art. 20 | < 5/mÃªs | Mensal |

---

## 13. ExceÃ§Ãµes e ViolaÃ§Ãµes

### 13.1 Processo de ExceÃ§Ã£o

ExceÃ§Ãµes a esta polÃ­tica devem:
1. Ser solicitadas formalmente ao CAIO
2. Incluir justificativa de negÃ³cio
3. Identificar riscos e mitigaÃ§Ãµes alternativas
4. Ser aprovadas pelo ComitÃª de IA (para Alto/CrÃ­tico)
5. Ter prazo definido (mÃ¡ximo 6 meses)
6. Ser documentadas e revisadas

### 13.2 ConsequÃªncias de ViolaÃ§Ãµes

| Gravidade | Exemplos | ConsequÃªncias |
|-----------|----------|---------------|
| Leve | Uso de ferramenta nÃ£o aprovada para tarefas de baixo risco | AdvertÃªncia verbal, treinamento |
| Moderada | Envio de dados internos para LLM pÃºblico | AdvertÃªncia formal, suspensÃ£o de acesso |
| Grave | Envio de dados de clientes para LLM pÃºblico, discriminaÃ§Ã£o por IA | DemissÃ£o, possÃ­vel aÃ§Ã£o legal |
| CrÃ­tica | Vazamento massivo de dados, dano a clientes | DemissÃ£o por justa causa, aÃ§Ã£o legal |

---

## 14. RevisÃ£o e AtualizaÃ§Ã£o

Esta polÃ­tica serÃ¡ revisada:
- **Anualmente** em condiÃ§Ãµes normais
- **Imediatamente** se houver:
  - Nova regulamentaÃ§Ã£o aplicÃ¡vel
  - Incidente significativo de IA
  - MudanÃ§a material na estratÃ©gia de IA
  - AquisiÃ§Ã£o de nova tecnologia de IA

---

## 15. AprovaÃ§Ãµes

| Papel | Nome | Data | Assinatura |
|-------|------|------|------------|
| CAIO | [Nome] | Jan 2025 | [Assinatura] |
| CISO | [Nome] | Jan 2025 | [Assinatura] |
| DPO | [Nome] | Jan 2025 | [Assinatura] |
| CLO (JurÃ­dico) | [Nome] | Jan 2025 | [Assinatura] |
| CEO | [Nome] | Jan 2025 | [Assinatura] |

---

## 16. ReferÃªncias

### Frameworks Utilizados

- [Microsoft Responsible AI Standard](https://www.microsoft.com/en-us/ai/responsible-ai)
- [Google AI Principles](https://ai.google/principles/)
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
- [ISO/IEC 42001:2023 - AI Management System](https://www.iso.org/standard/81230.html)
- [OECD AI Principles](https://oecd.ai/en/ai-principles)
- [LGPD - Lei 13.709/2018](http://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/L13709.htm)
- [EU AI Act](https://artificialintelligenceact.eu/)

---

*Exemplo educacional baseado em melhores prÃ¡ticas de IA responsÃ¡vel - MBA CiberseguranÃ§a & IA*
